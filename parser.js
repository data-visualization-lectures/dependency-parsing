/**
 * parser.js - Japanese Dependency Parser
 * Uses kuromoji.js for morphological analysis and rule-based dependency estimation
 */

class DependencyParser {
    constructor() {
        this.tokenizer = null;
        this.initialized = false;
    }

    /**
     * Initialize the kuromoji tokenizer
     */
    async initialize() {
        if (this.initialized) {
            console.log('‚úÖ Parser already initialized');
            return;
        }

        console.log('üì• Starting kuromoji initialization...');
        console.log('üìç Dictionary path: https://cdn.jsdelivr.net/npm/kuromoji@0.1.2/dict');

        return new Promise((resolve, reject) => {
            try {
                const builder = kuromoji.builder({
                    dicPath: "https://cdn.jsdelivr.net/npm/kuromoji@0.1.2/dict"
                });

                console.log('‚è≥ Building kuromoji...');

                builder.build((err, tokenizer) => {
                    if (err) {
                        console.error('‚ùå Kuromoji build error:', err);
                        reject(err);
                        return;
                    }

                    this.tokenizer = tokenizer;
                    this.initialized = true;
                    console.log('‚úÖ Kuromoji tokenizer initialized successfully');
                    resolve();
                });
            } catch (error) {
                console.error('‚ùå Kuromoji initialization error:', error);
                reject(error);
            }
        });
    }

    /**
     * Parse text and extract dependency structure
     * @param {string} text - Input Japanese text
     * @returns {Object} Parsed result with bunsetsu and dependencies
     */
    parse(text) {
        if (!this.initialized || !this.tokenizer) {
            throw new Error('Parser not initialized');
        }

        // Tokenize the text
        const tokens = this.tokenizer.tokenize(text);

        // Group tokens into bunsetsu (phrases)
        const bunsetsuList = this.groupIntoBunsetsu(tokens);

        // Estimate dependencies between bunsetsu
        const dependencies = this.estimateDependencies(bunsetsuList);

        return {
            bunsetsu: bunsetsuList,
            dependencies: dependencies,
            tokens: tokens
        };
    }

    /**
     * Group morphemes into bunsetsu (ÊñáÁØÄ)
     * A bunsetsu typically consists of content words followed by function words
     */
    groupIntoBunsetsu(tokens) {
        const bunsetsuList = [];
        let currentBunsetsu = [];

        for (let i = 0; i < tokens.length; i++) {
            const token = tokens[i];
            currentBunsetsu.push(token);

            // Check if this is the end of a bunsetsu
            // End conditions:
            // 1. Next token is a content word (noun, verb, adjective, etc.)
            // 2. Current token is a punctuation
            // 3. This is the last token

            const isLastToken = i === tokens.length - 1;
            const isPunctuation = token.pos === 'Ë®òÂè∑';

            let shouldEndBunsetsu = isLastToken || isPunctuation;

            if (!shouldEndBunsetsu && i < tokens.length - 1) {
                const nextToken = tokens[i + 1];
                const currentIsFunction = this.isFunctionWord(token);
                const nextIsContent = this.isContentWord(nextToken);

                // End bunsetsu if current is function word and next is content word
                shouldEndBunsetsu = currentIsFunction && nextIsContent;
            }

            if (shouldEndBunsetsu && currentBunsetsu.length > 0) {
                bunsetsuList.push({
                    id: bunsetsuList.length,
                    tokens: currentBunsetsu,
                    surface: currentBunsetsu.map(t => t.surface_form).join(''),
                    head: this.findHead(currentBunsetsu)
                });
                currentBunsetsu = [];
            }
        }

        return bunsetsuList;
    }

    /**
     * Check if a token is a content word
     */
    isContentWord(token) {
        const contentPOS = ['ÂêçË©û', 'ÂãïË©û', 'ÂΩ¢ÂÆπË©û', 'ÂâØË©û', 'ÈÄ£‰ΩìË©û', 'ÊÑüÂãïË©û'];
        return contentPOS.includes(token.pos);
    }

    /**
     * Check if a token is a function word
     */
    isFunctionWord(token) {
        const functionPOS = ['Âä©Ë©û', 'Âä©ÂãïË©û', 'Êé•Á∂öË©û'];
        return functionPOS.includes(token.pos);
    }

    /**
     * Find the head (main) token in a bunsetsu
     */
    findHead(tokens) {
        // Priority: ÂãïË©û > ÂΩ¢ÂÆπË©û > ÂêçË©û > „Åù„ÅÆ‰ªñ
        const priorities = {
            'ÂãïË©û': 3,
            'ÂΩ¢ÂÆπË©û': 2,
            'ÂêçË©û': 1
        };

        let head = tokens[0];
        let maxPriority = priorities[head.pos] || 0;

        for (const token of tokens) {
            const priority = priorities[token.pos] || 0;
            if (priority > maxPriority) {
                head = token;
                maxPriority = priority;
            }
        }

        return head;
    }

    /**
     * Estimate dependency relationships between bunsetsu
     * Improved rule-based approach for Japanese dependency parsing
     */
    estimateDependencies(bunsetsuList) {
        const dependencies = [];

        for (let i = 0; i < bunsetsuList.length - 1; i++) {
            const source = bunsetsuList[i];
            let targetIndex = this.findDependencyTarget(source, i, bunsetsuList);

            dependencies.push({
                from: i,
                to: targetIndex,
                label: this.getDependencyLabel(source, bunsetsuList[targetIndex])
            });
        }

        return dependencies;
    }

    /**
     * Find the dependency target for a bunsetsu using improved heuristics
     */
    findDependencyTarget(source, sourceIndex, bunsetsuList) {
        const lastToken = source.tokens[source.tokens.length - 1];
        const sourceHead = source.head;

        // Rule 1: Check for clause-ending patterns („Å¶„ÄÅ„Åß„ÄÅ„Åå„ÄÅetc.)
        // These often connect to distant predicates
        if (this.isClauseConnector(lastToken)) {
            return this.findNextPredicate(sourceIndex, bunsetsuList);
        }

        // Rule 2: Case particles (Ê†ºÂä©Ë©û) typically attach to the nearest verb
        if (lastToken.pos === 'Âä©Ë©û') {
            const particle = lastToken.surface_form;

            // Subject/object markers look for verbs
            if (['„ÅØ', '„Åå', '„Çí', '„Å´', '„Å∏', '„Åß', '„Åã„Çâ', '„Åæ„Åß', '„Çà„Çä', '„Å®'].includes(particle)) {
                return this.findNextVerb(sourceIndex, bunsetsuList);
            }

            // „ÅÆ (possessive/modification) attaches to the next noun
            if (particle === '„ÅÆ') {
                return this.findNextNoun(sourceIndex, bunsetsuList);
            }
        }

        // Rule 3: Adverbs and adnominals modify the next predicate/noun
        if (sourceHead.pos === 'ÂâØË©û') {
            return this.findNextPredicate(sourceIndex, bunsetsuList);
        }

        if (sourceHead.pos === 'ÈÄ£‰ΩìË©û') {
            return this.findNextNoun(sourceIndex, bunsetsuList);
        }

        // Rule 4: Nouns without particles typically modify the next element
        if (sourceHead.pos === 'ÂêçË©û' && lastToken.pos !== 'Âä©Ë©û') {
            // Look for the next noun or verb
            for (let j = sourceIndex + 1; j < bunsetsuList.length; j++) {
                const candidate = bunsetsuList[j];
                if (candidate.head.pos === 'ÂêçË©û' || candidate.head.pos === 'ÂãïË©û') {
                    return j;
                }
            }
        }

        // Rule 5: Verbs in non-final form (ÈÄ£Áî®ÂΩ¢„ÄÅÈÄ£‰ΩìÂΩ¢) modify the next element
        if (sourceHead.pos === 'ÂãïË©û') {
            const conjugation = sourceHead.pos_detail_1;
            if (conjugation !== 'Ëá™Á´ã' || lastToken.surface_form.match(/[„Å¶„Åß„Åü„Çä„Å™„Åå„Çâ]/)) {
                return this.findNextPredicate(sourceIndex, bunsetsuList);
            }
        }

        // Default: attach to the next bunsetsu
        return sourceIndex + 1;
    }

    /**
     * Check if a token is a clause connector
     */
    isClauseConnector(token) {
        if (token.pos === 'Âä©Ë©û') {
            return ['„Å¶', '„Åß', '„Å∞', '„Å®', '„Å¶„ÇÇ', '„Åß„ÇÇ', '„Åã„Çâ', '„ÅÆ„Åß', '„ÅÆ„Å´', '„Åë„Å©', '„Åå'].includes(token.surface_form);
        }
        if (token.pos === 'Âä©ÂãïË©û') {
            return ['„Åü', '„Å†', '„Åß„Åô', '„Åæ„Åô'].includes(token.basic_form);
        }
        return false;
    }

    /**
     * Find the next verb bunsetsu
     */
    findNextVerb(fromIndex, bunsetsuList) {
        for (let j = fromIndex + 1; j < bunsetsuList.length; j++) {
            if (bunsetsuList[j].head.pos === 'ÂãïË©û') {
                return j;
            }
        }
        // If no verb found, attach to the last bunsetsu (usually the main predicate)
        return bunsetsuList.length - 1;
    }

    /**
     * Find the next noun bunsetsu
     */
    findNextNoun(fromIndex, bunsetsuList) {
        for (let j = fromIndex + 1; j < bunsetsuList.length; j++) {
            if (bunsetsuList[j].head.pos === 'ÂêçË©û') {
                return j;
            }
        }
        // Default to next bunsetsu
        return fromIndex + 1;
    }

    /**
     * Find the next predicate (verb or adjective) bunsetsu
     */
    findNextPredicate(fromIndex, bunsetsuList) {
        for (let j = fromIndex + 1; j < bunsetsuList.length; j++) {
            const head = bunsetsuList[j].head;
            if (head.pos === 'ÂãïË©û' || head.pos === 'ÂΩ¢ÂÆπË©û') {
                return j;
            }
        }
        // If no predicate found, attach to the last bunsetsu
        return bunsetsuList.length - 1;
    }

    /**
     * Get a label for the dependency relationship
     */
    getDependencyLabel(source, target) {
        const lastToken = source.tokens[source.tokens.length - 1];

        if (lastToken.pos === 'Âä©Ë©û') {
            return lastToken.surface_form;
        }

        return '';
    }
}

// Create a global instance
const parser = new DependencyParser();
